key Models for Image


Vision Transformer

Sequence 2 Sequence 모델 요약
  • 기존 딥러닝 모델은 입력과 출력 차원이 모두 고정된 사이즈로 제한되는 문제를 가지고 있다.
  • 예를 들어, 번역모델을 만든다면 입력과 출력은 문장마다 다를 수 있다.
  • Sequence 2 Sequence 모델은 이를 해결하고자 한 모델이다.
  • Sequence 2 Sequence 모델 구조
    • 인코더와 디코더로 구성되며 내부에는 크게 2개의 RNN계열 모델 기반으로 구성됨
    • 인코더는 입력 문장은 순차적으로 입력받은 후 모든 단어 정보를 압축해서 Context Vector로 만든다.
    • 이를 디코더로 전송하여 디코더는 Context Vector를 기반으로 번역된 단어를 순서대로 출력한다.
  • Sequence 2 Sequence 모델 문제점
    • 입력 데이터가 매우 길다면 1. 이를 함축하여 Context Vector로 만들게 될 경우 정보 손실이 될 수 있음
    • 2. RNN계열의 근본적인 이슈는 Gradinet Vanishing 문제가 존재한다.
  • 이를 해결하기위해 나온 개념이 Attention

Attention 요약
  • 기본 아이디어
    • 디코더에서 출력 단어를 예측할때마다 인코더에서 들어온 전체 입력 문장을 참고하되,
    • 전체 입력 문장을 모두 동일 비율로 참고하는것이 아니라
    • 해당 시점에 예측해야할 단어와 관련된 입력 단어에 조금 더 높은 비율을 두어 참고하는것
    • 입력과 출력이 서로 대응되는 정보에 대해서는 유사한 hidden state 결과값을 가질것이라고 가정하기 때문이다.
  • Attention 동작 과정 요약
    • 인코더에서 각 입력마다 hidden state를 만든다.
    • 디코더의 출력때마다, 당시의 디코더의 hidden state와 인코더의 hidden state간의 유사도를 계산(유사한 입력과 출력 정보를 찾기위해)
    • 유사도가 높은 hidden state를 집중해서 반영하기위해 유사도 정도를 softmax 등을 통해 계산
      • 유사도가 높은 입력 정보만 집중(Attention)하는것이다.
    • 이를 기반으로 Context Vector를 만든다.
      • 즉, 모든 입력 정보를 압축하는것이 아니라 유사도가 높은 입력 정보를 중심으로 압축한다.
    • 이를 기반으로 디코더 출력값을 계산한다.
    • Attention 동작을 실제 구현하기위해 다양한 수학적 계산식이 제안되었다.

참고: Attention Score 계산 예
  • Attention Score 계산
    • score(s_t, h_i) = s_t(전치) * h_i
      • t(time step)의 디코더 hidden state)를 s_t라고 정의
      • s_t(전치)는 디코더에서 현재 시점의 t의 은닉 벡터를 전치시킨것(왜냐하면 한개의 히든 스테이트(스텝)니까(예: (4, 1)))
      • 인코더의 t(time step) 시점의 인코더의 각 hidden state 1, 2, 3, ...N에 해당하는 은닉 상태(hidden state) 값을 각각 h_1, h_2, h_3, ...h_N이라고 정의
  • s_t와 인코더의 모든 hidden state(현재 시점 t)의 Attention Score의 모음 값을 e(t)로 정의하면,
    • e(t) = [s_t(전치) * h_1, s_t(전치) * h_2, s_t(전치) * h_3, ..., s_t(전치) * h_N]
  • 이를 softmax에 넣어, 각 hidden state의 어텐션 가중치(Attention Weight)를 구한다.
    • α(t) = softmax(e(t))
  • 각 어텐션 가중치와 hidden state 값을 곱하여 어텐션 값(Attention Value)를 구한다.
    • a_t = α_i(t) * h_i들의 합(i는 N)
    • 바로 이 a_t가 Context Vector가 된다.
