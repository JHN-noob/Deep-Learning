{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "462c0a8e-ca57-485a-8201-168b375599aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris['data'] # (150, 4)\n",
    "y = iris['target'] # (150, ), 각 원소는 출력에서 정답의 인덱스 번호를 의미하는듯함\n",
    "names = iris['target_names'] # 3종류\n",
    "feature_names = iris['feature_names'] # 4개의 feature\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b14996c0-2bbb-41f7-9d46-f8816e5e3ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 4]) torch.Size([30, 4]) torch.Size([120]) torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "std_scaler = StandardScaler()\n",
    "std_scaler.fit(X_train)\n",
    "X_train_tensor = torch.from_numpy(std_scaler.transform(X_train)).float()\n",
    "X_test_tensor = torch.from_numpy(std_scaler.transform(X_test)).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).long()\n",
    "y_test_tensor = torch.from_numpy(y_test).long()\n",
    "\n",
    "print(X_train_tensor.shape, X_test_tensor.shape, y_train_tensor.shape, y_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb37ef14-f441-49f3-8eb0-2fc321c57ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 1000\n",
    "minibatch_size = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f12d43a0-9eed-4896-ab55-5ca93c071409",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 100),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(100, 20),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(20, 5),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(5, output_dim),\n",
    "            nn.LogSoftmax(dim=-1) # 최종 출력은 3이 되므로 dim=-1로 적용되는 차원을 지정해준다.\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.linear_layers(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ecad03e7-9d51-4277-ab98-18151d47ac62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train_tensor.size(-1)\n",
    "output_dim = 3\n",
    "print(input_dim, output_dim)\n",
    "model = FunModel(input_dim, output_dim)\n",
    "\n",
    "loss_func = nn.NLLLoss() # logsoftmax를 썼으므로 NNL Loss를 써준다.\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07b8b9e2-dc19-415d-8bb5-c6a8152262f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(1.0798, grad_fn=<DivBackward0>)\n",
      "100 tensor(0.2101, grad_fn=<DivBackward0>)\n",
      "200 tensor(0.0447, grad_fn=<DivBackward0>)\n",
      "300 tensor(0.0323, grad_fn=<DivBackward0>)\n",
      "400 tensor(0.0240, grad_fn=<DivBackward0>)\n",
      "500 tensor(0.0161, grad_fn=<DivBackward0>)\n",
      "600 tensor(0.0094, grad_fn=<DivBackward0>)\n",
      "700 tensor(0.0051, grad_fn=<DivBackward0>)\n",
      "800 tensor(0.0029, grad_fn=<DivBackward0>)\n",
      "900 tensor(0.0018, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for index in range(nb_epochs):\n",
    "    indices = torch.randperm(X_train_tensor.size(0))\n",
    "\n",
    "    x_batch_list = torch.index_select(X_train_tensor, 0, index=indices)\n",
    "    y_batch_list = torch.index_select(y_train_tensor, 0, index=indices)\n",
    "    x_batch_list = x_batch_list.split(minibatch_size, 0)\n",
    "    y_batch_list = y_batch_list.split(minibatch_size, 0)\n",
    "\n",
    "    epoch_loss = list()\n",
    "    for x_minibatch, y_minibatch in zip(x_batch_list, y_batch_list):\n",
    "        y_minibatch_pred = model(x_minibatch)\n",
    "        loss = loss_func(y_minibatch_pred, y_minibatch)\n",
    "        epoch_loss.append(loss)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (index % 100) == 0:\n",
    "        print(index, sum(epoch_loss) / len(epoch_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99efe65f-d744-4997-bd88-dc94245dd78f",
   "metadata": {},
   "source": [
    "# 테스트셋 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e40bdd17-1d2b-4839-9747-508cbd975846",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_test_pred = model(X_test_tensor)\n",
    "    # torch.argmax(x, dim=차원), 특정 차원의 데이터 중 가장 높은 값(확률)의 index 번호를 리턴\n",
    "    y_pred_list = torch.argmax(y_test_pred, dim=1) # (30, 3)에서 3개의 feature 중에 가장 높은 값(확률)의 index 번호가 저장됨([0.2, 0.5, 0.3]이면 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6324ba85-5db6-44df-a3c9-e371fad3107f",
   "metadata": {},
   "source": [
    "# 미니배치 사이즈 기반 예측(기존내용 복습)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5b49fb8-ea9a-4d27-b42d-0e5982364227",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = list()\n",
    "x_test_batch_list = X_test_tensor.split(minibatch_size, 0)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x_minibatch in x_test_batch_list:\n",
    "        y_test_pred = model(x_minibatch)\n",
    "        # torch.Size([30, 3])\n",
    "        y_test_pred = torch.argmax(y_test_pred, dim=1)\n",
    "        # torch.Size([30, ])\n",
    "        y_pred_list.extend(y_test_pred.squeeze().detach().tolist())\n",
    "\n",
    "y_pred_list = torch.tensor(y_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "546717dc-0d4c-427e-a3b9-32d4144ff7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30]) torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_list.shape, y_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4d0cc0-2955-465f-9454-c1512155d1a6",
   "metadata": {},
   "source": [
    "# Multi-Label Classfication 기본 메트릭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8746794b-2621-4c51-bd2a-244a78111871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  0 10]]\n",
      "Precision List:\t [1.         1.         0.90909091]\n",
      "Macro Precision:\t 0.9696969696969697\n",
      "Macro Precision Formula: 0.9696969696969697\n",
      "Micro Precision:\t 0.9666666666666667\n",
      "Recall List:\t [1.         1.         0.90909091]\n",
      "Macro Recall:\t 0.9666666666666667\n",
      "Macro Recall:\t 0.9666666666666667\n",
      "Macro F1 Score List:\t [1.         1.         0.90909091]\n",
      "Macro F1 Score:\t 0.9665831244778612\n",
      "Micro F1 Score:\t 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"Confusion Matrix\\n\", str(confusion_matrix(y_test_tensor, y_pred_list)))\n",
    "print(\"Precision List:\\t\", str(precision_score(y_test_tensor, y_pred_list, average=None)))\n",
    "print(\"Macro Precision:\\t\", str(precision_score(y_test_tensor, y_pred_list, average='macro')))\n",
    "print(\"Macro Precision Formula:\", str(sum(precision_score(y_test_tensor, y_pred_list, average=None)) / 3))\n",
    "print(\"Micro Precision:\\t\", str(precision_score(y_test_tensor, y_pred_list, average='micro')))\n",
    "\n",
    "print(\"Recall List:\\t\", str(precision_score(y_test_tensor, y_pred_list, average=None)))\n",
    "print(\"Macro Recall:\\t\", str(recall_score(y_test_tensor, y_pred_list, average='macro')))\n",
    "print(\"Macro Recall:\\t\", str(recall_score(y_test_tensor, y_pred_list, average='micro')))\n",
    "\n",
    "print(\"Macro F1 Score List:\\t\", str(precision_score(y_test_tensor, y_pred_list, average=None)))\n",
    "print(\"Macro F1 Score:\\t\", str(f1_score(y_test_tensor, y_pred_list, average='macro')))\n",
    "print(\"Micro F1 Score:\\t\", str(f1_score(y_test_tensor, y_pred_list, average='micro')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
