{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fb192b2-84f3-41f2-b3e9-0029bfbd6b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Linear(in_features=input_dim, out_features=output_dim)\n",
    "        # self.activation = nn.Sigmoid()\n",
    "        self.activation = nn.ReLU()\n",
    "        # self.activation = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.activation(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf6b30fa-85d3-46a0-b8ce-42181304e455",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(4)\n",
    "y = torch.zeros(3)\n",
    "model = LinearRegressionModel(4, 3)\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60b4f923-6157-4dd5-a051-4771b2943630",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "nb_epochs = 1000\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(nb_epochs+1):\n",
    "    y_pred = model(x)\n",
    "    loss = loss_function(y_pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9392fcf7-93f8-45b7-a9b8-16623ff03f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5165e-14, grad_fn=<MseLossBackward0>) tensor([5.9605e-08, 0.0000e+00, 2.6822e-07], grad_fn=<ReluBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[ 0.2050, -0.2040,  0.2042, -0.0086],\n",
      "        [-0.4367, -0.0392, -0.1299, -0.4748],\n",
      "        [ 0.1947,  0.0783, -0.5155,  0.0492]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1967, -0.1552,  0.1932], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(loss, y_pred)\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbf190c-7450-4d6e-b234-443e9ce4d29c",
   "metadata": {},
   "source": [
    "# 다층 레이어 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e25d923-e315-400d-b04b-eac52ab03354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(input_dim, 10)\n",
    "        self.linear2 = nn.Linear(10, 10)\n",
    "        self.linear3 = nn.Linear(10, 10)\n",
    "        self.linear4 = nn.Linear(10, output_dim)\n",
    "        # self.activation = nn.Sigmoid()\n",
    "        # self.activation = nn.ReLU()\n",
    "        self.activation = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.activation(self.linear1(x))\n",
    "        hidden = self.activation(self.linear2(hidden))\n",
    "        hidden = self.activation(self.linear3(hidden))\n",
    "        y = self.linear4(hidden) # 마지막 출력에는 활성화 함수를 사용하지않는 것이 일반적임\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ea755e4-d7aa-4c39-afbc-a5878d58a6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(4)\n",
    "y = torch.zeros(3)\n",
    "model = LinearRegressionModel(4, 3)\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "823226e4-f3dd-4e35-a187-1a832797bcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "nb_epochs = 1000\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(nb_epochs+1):\n",
    "    y_pred = model(x)\n",
    "    loss = loss_function(y_pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc446f28-6c1b-4bab-8e2e-cba14d0aa64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.9134e-11, grad_fn=<MseLossBackward0>) tensor([ 3.3528e-08, -6.6573e-06, -1.3895e-05], grad_fn=<ViewBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[ 0.4082, -0.2242,  0.3183,  0.4643],\n",
      "        [-0.3961,  0.4747, -0.4720,  0.1354],\n",
      "        [-0.4439,  0.4988, -0.4460,  0.3742],\n",
      "        [ 0.3248, -0.0241, -0.4255, -0.3969],\n",
      "        [ 0.2883, -0.4850, -0.4940,  0.2846],\n",
      "        [ 0.0863, -0.0959, -0.4824,  0.2551],\n",
      "        [-0.0040,  0.2634, -0.1946, -0.2441],\n",
      "        [ 0.4320, -0.1047, -0.1741,  0.0495],\n",
      "        [ 0.2812,  0.2909,  0.0019, -0.1788],\n",
      "        [ 0.2893,  0.0153,  0.0577, -0.1594]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3903, -0.3262,  0.2574, -0.3179,  0.2655, -0.2225,  0.2896, -0.2406,\n",
      "        -0.4350,  0.1507], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2061,  0.2750, -0.3079, -0.2681,  0.2034, -0.2610, -0.2402,  0.2362,\n",
      "         -0.1808, -0.1721],\n",
      "        [ 0.1829, -0.2048,  0.0766, -0.0930, -0.2549,  0.2891,  0.1830, -0.2838,\n",
      "          0.0435, -0.2442],\n",
      "        [-0.2454, -0.1052,  0.0628,  0.2827,  0.1214, -0.0801,  0.0955,  0.2758,\n",
      "         -0.2155,  0.0801],\n",
      "        [ 0.0234,  0.3007, -0.1858, -0.0085, -0.0212, -0.3049,  0.2223, -0.1644,\n",
      "          0.1590,  0.1538],\n",
      "        [ 0.2743, -0.1869, -0.1232, -0.1355, -0.0953, -0.2712,  0.0609, -0.0119,\n",
      "          0.2989,  0.0707],\n",
      "        [-0.1849,  0.2579, -0.2353, -0.0140, -0.2899,  0.3029, -0.2566, -0.0467,\n",
      "         -0.1680,  0.0438],\n",
      "        [ 0.2236,  0.0632,  0.1301,  0.2579, -0.2703, -0.2807, -0.2201, -0.0974,\n",
      "         -0.2790, -0.1952],\n",
      "        [ 0.2805,  0.2288, -0.2605,  0.2502,  0.0084, -0.0856, -0.0960, -0.2783,\n",
      "          0.2294,  0.1396],\n",
      "        [-0.1175,  0.2870, -0.1757,  0.0452,  0.1832, -0.0870, -0.1367,  0.2786,\n",
      "          0.2914, -0.0528],\n",
      "        [ 0.0717, -0.2654, -0.1731, -0.0929, -0.0035,  0.0915,  0.2795,  0.1432,\n",
      "         -0.1018, -0.3078]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1909,  0.2678, -0.1151, -0.2941,  0.1036,  0.1007,  0.2018,  0.1157,\n",
      "        -0.0764, -0.2441], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2237, -0.1220, -0.3022, -0.3078, -0.0234,  0.1117, -0.1451,  0.0066,\n",
      "          0.0973,  0.2493],\n",
      "        [ 0.1540,  0.3199,  0.1304, -0.2179,  0.0324, -0.2943,  0.3187, -0.0736,\n",
      "          0.0488, -0.1656],\n",
      "        [-0.1837, -0.1916, -0.1305, -0.2788,  0.2001, -0.1420,  0.2223,  0.1111,\n",
      "         -0.0068,  0.2144],\n",
      "        [ 0.1567,  0.1207,  0.0270, -0.0702, -0.2571, -0.2266, -0.3149, -0.1582,\n",
      "         -0.0596, -0.1987],\n",
      "        [ 0.1849, -0.1714,  0.0632,  0.0864, -0.2215,  0.1218, -0.3080,  0.1189,\n",
      "         -0.0874, -0.0939],\n",
      "        [ 0.1764,  0.2375, -0.0915,  0.0685,  0.1268, -0.3105,  0.2675, -0.1181,\n",
      "          0.0123, -0.0318],\n",
      "        [-0.0606, -0.0320,  0.0647, -0.1688, -0.2181,  0.2083,  0.1684,  0.0234,\n",
      "         -0.1145, -0.1029],\n",
      "        [ 0.1199,  0.1085, -0.0301, -0.1710, -0.2383, -0.0296, -0.2450, -0.2578,\n",
      "          0.2150,  0.2927],\n",
      "        [-0.0944,  0.2116, -0.1298, -0.0930, -0.2874,  0.2198,  0.2485,  0.2273,\n",
      "         -0.2757, -0.3028],\n",
      "        [-0.1949,  0.1622, -0.1294,  0.1523, -0.1452, -0.2645, -0.3053, -0.2372,\n",
      "         -0.0131,  0.2834]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2092,  0.1139, -0.0277,  0.2693, -0.2040,  0.2203,  0.1851,  0.2408,\n",
      "        -0.2909, -0.0632], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0749,  0.0996, -0.1932, -0.1142,  0.2319,  0.1490, -0.2755,  0.1291,\n",
      "         -0.2057,  0.2659],\n",
      "        [-0.2275, -0.1810, -0.2304,  0.2708,  0.0710,  0.1333,  0.2483,  0.0480,\n",
      "          0.1476, -0.0504],\n",
      "        [ 0.0906,  0.1706,  0.0825,  0.0139, -0.1556, -0.0303, -0.1216,  0.0914,\n",
      "          0.0028, -0.0109]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0263,  0.0025, -0.0519], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(loss, y_pred)\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f392b980-cc6a-4169-b578-f7573b2ecbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(4)\n",
    "y = torch.zeros(3)\n",
    "input_dim = x.size(0)\n",
    "output_dim = y.size(0)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_dim, 10),\n",
    "    nn.LeakyReLU(0.1),\n",
    "    nn.Linear(10, 10),\n",
    "    nn.LeakyReLU(0.1),\n",
    "    nn.Linear(10, 10),\n",
    "    nn.LeakyReLU(0.1),\n",
    "    nn.Linear(10, output_dim)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a5184bb-c9fb-453d-891e-d51dcb25cce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.0484e-13, grad_fn=<MseLossBackward0>) tensor([-6.9663e-07, -4.0233e-07,  9.3132e-07], grad_fn=<ViewBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[-0.1316,  0.3044, -0.2506,  0.4329],\n",
      "        [-0.0340, -0.2885, -0.3310, -0.3434],\n",
      "        [-0.0438, -0.0910, -0.4147,  0.1563],\n",
      "        [ 0.1273, -0.3213, -0.0744,  0.3222],\n",
      "        [-0.0434,  0.2286, -0.4020,  0.4764],\n",
      "        [-0.1578, -0.3858,  0.0248, -0.0901],\n",
      "        [-0.2886,  0.4622,  0.2869, -0.1040],\n",
      "        [-0.3060,  0.1483, -0.3616,  0.0512],\n",
      "        [ 0.1856,  0.4484,  0.4565, -0.4846],\n",
      "        [ 0.2898,  0.0970, -0.2105, -0.1609]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1966, -0.2068,  0.0364,  0.3109, -0.0359,  0.1440,  0.4814, -0.2367,\n",
      "        -0.1686,  0.4594], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2925, -0.3080, -0.1044, -0.1796, -0.1254, -0.1158,  0.0774,  0.2063,\n",
      "         -0.2110,  0.1901],\n",
      "        [ 0.2637,  0.2183,  0.0645, -0.1972, -0.1961, -0.0828,  0.2845,  0.1709,\n",
      "          0.0260,  0.3007],\n",
      "        [ 0.2624,  0.0926,  0.1872, -0.1191, -0.0545,  0.1728,  0.2740,  0.0492,\n",
      "         -0.1010,  0.1843],\n",
      "        [-0.0794,  0.1179,  0.0298,  0.1850, -0.1139,  0.1830,  0.2382,  0.0969,\n",
      "          0.2613, -0.0264],\n",
      "        [-0.1864, -0.2339,  0.0168,  0.0975,  0.0095, -0.0736, -0.1488,  0.2065,\n",
      "         -0.1816, -0.1857],\n",
      "        [-0.0570,  0.1584, -0.1608,  0.2398, -0.0903,  0.1257,  0.1252,  0.2563,\n",
      "         -0.1725, -0.0381],\n",
      "        [ 0.0948, -0.0052,  0.0445, -0.2040,  0.0691,  0.0686, -0.0834,  0.1268,\n",
      "         -0.2242, -0.1963],\n",
      "        [ 0.1038, -0.2735, -0.1081,  0.0266,  0.1067, -0.0819, -0.2139, -0.0546,\n",
      "          0.0723, -0.0246],\n",
      "        [-0.0017, -0.0628,  0.1159,  0.2380, -0.1025, -0.2710, -0.0905, -0.0950,\n",
      "          0.1005, -0.2062],\n",
      "        [-0.0012,  0.1194,  0.2444,  0.2724, -0.2414,  0.1884, -0.1557,  0.2634,\n",
      "          0.2913, -0.2175]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0941,  0.2146,  0.1076,  0.0867,  0.2383, -0.2156, -0.1682, -0.1672,\n",
      "         0.1504,  0.3093], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1796, -0.2143, -0.2101,  0.2173,  0.0195,  0.1402, -0.0904,  0.2004,\n",
      "          0.1782,  0.1110],\n",
      "        [-0.0322,  0.0644, -0.1080, -0.1858, -0.2943, -0.0053, -0.1731, -0.0494,\n",
      "         -0.1508,  0.2700],\n",
      "        [-0.2186, -0.1998, -0.0499, -0.1740,  0.1002,  0.0240,  0.1355, -0.2421,\n",
      "         -0.0979,  0.2287],\n",
      "        [-0.1390,  0.1472,  0.2498, -0.0041, -0.2114,  0.1230, -0.2583, -0.3153,\n",
      "          0.2842,  0.2281],\n",
      "        [ 0.2622, -0.0881,  0.0472,  0.2980,  0.1770, -0.2910, -0.1581,  0.1853,\n",
      "          0.1160, -0.2397],\n",
      "        [-0.0269,  0.3221,  0.1939,  0.2087,  0.0129,  0.3066,  0.2126, -0.0963,\n",
      "         -0.0692,  0.1579],\n",
      "        [ 0.2590,  0.0430,  0.1154,  0.1449, -0.1919,  0.0640,  0.0262,  0.1492,\n",
      "          0.2248, -0.2537],\n",
      "        [-0.2539, -0.3064,  0.0013,  0.2362,  0.0475, -0.3015, -0.1753, -0.1638,\n",
      "          0.0708, -0.0760],\n",
      "        [ 0.1713, -0.1086,  0.2433, -0.0532,  0.1667, -0.0474, -0.1345, -0.0120,\n",
      "          0.3047, -0.2159],\n",
      "        [-0.1785, -0.0943,  0.0567, -0.1142, -0.1267, -0.0158,  0.2286, -0.2299,\n",
      "         -0.0274, -0.1136]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1906, -0.2502,  0.1877,  0.1595, -0.1967,  0.0684, -0.0084,  0.2886,\n",
      "         0.2927,  0.0811], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.3019, -0.0638, -0.3030,  0.0489, -0.2010,  0.1645,  0.2498,  0.1323,\n",
      "         -0.2657, -0.1215],\n",
      "        [-0.0108,  0.2976, -0.2053,  0.2427, -0.3111,  0.1920,  0.2857, -0.0757,\n",
      "          0.0864,  0.1354],\n",
      "        [-0.3208,  0.0032, -0.2852,  0.1797,  0.1643, -0.3145,  0.1931,  0.0213,\n",
      "          0.0129,  0.1480]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0337, -0.2206,  0.0640], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "learning_rate = 0.01\n",
    "nb_epochs = 1000\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(nb_epochs+1):\n",
    "    y_pred = model(x)\n",
    "    loss = loss_function(y_pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss, y_pred)\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36605124-b624-432a-94f2-a34b586c861b",
   "metadata": {},
   "source": [
    "# SGD 방식 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8418fbf9-8ff7-4c79-a757-16503b51cf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.1894, -0.2765,  0.8382, -1.9304],\n",
      "        [ 0.0274,  1.0628,  0.7160, -1.1517],\n",
      "        [-0.5813,  1.1983,  2.5135, -0.7826]])\n",
      "tensor([1, 2])\n",
      "tensor([[ 0.0274,  1.0628,  0.7160, -1.1517],\n",
      "        [-0.5813,  1.1983,  2.5135, -0.7826]])\n",
      "tensor([[-0.2765,  0.8382],\n",
      "        [ 1.0628,  0.7160],\n",
      "        [ 1.1983,  2.5135]])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.randn(3, 4)\n",
    "print(data1)\n",
    "indices = torch.tensor([1, 2])\n",
    "print(indices)\n",
    "print(torch.index_select(data1, 0, indices))\n",
    "print(torch.index_select(data1, 1, indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "170400c2-d0bd-4379-bd4e-6628e6537cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(5000, 10)\n",
    "y = torch.zeros(5000, 1)\n",
    "learning_rate = 0.01\n",
    "nb_epochs = 1000\n",
    "minibatch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d805e9b6-6f38-45e8-8893-ea6fc6a326ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x.size(-1)\n",
    "output_dim = y.size(-1)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_dim, 10),\n",
    "    nn.LeakyReLU(0.1),\n",
    "    nn.Linear(10, 8),\n",
    "    nn.LeakyReLU(0.1),\n",
    "    nn.Linear(8, 6),\n",
    "    nn.LeakyReLU(0.1),\n",
    "    nn.Linear(6, output_dim)\n",
    ")\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e78da55b-17e4-4c71-986f-301634a39371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3550, 4356, 3043,  ..., 3480, 1415, 2163])\n"
     ]
    }
   ],
   "source": [
    "indices = torch.randperm(x.size(0)) # 5000개의 인덱스 번호를 만들어서 섞음\n",
    "print(indices)\n",
    "x_batch_list = torch.index_select(x, 0, index=indices) # indices로 데이터셋을 shuffle\n",
    "y_batch_list = torch.index_select(y, 0, index=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9bba373-c334-4965-9710-5313c7f8cdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch_list[0].shape\n",
    "x_batch_list = x_batch_list.split(minibatch_size, dim=0) # 행을 기준으로 미니배치 사이즈로 나눈다\n",
    "y_batch_list = y_batch_list.split(minibatch_size, dim=0)\n",
    "print(len(x_batch_list), len(y_batch_list))\n",
    "type(y_batch_list)\n",
    "type(y_batch_list[0])\n",
    "x_batch_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c38afe3c-7a5b-483b-b1e7-1b784ad5dcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1974e-14, grad_fn=<MseLossBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[-0.2409,  0.3024,  0.0587, -0.0520,  0.1150,  0.0610, -0.1726,  0.3086,\n",
      "         -0.1511, -0.0019],\n",
      "        [ 0.1817, -0.0070, -0.1652, -0.1036, -0.1939, -0.1362,  0.2584,  0.2275,\n",
      "          0.2478,  0.2951],\n",
      "        [-0.0504, -0.2033, -0.1345, -0.0958,  0.3141, -0.2102,  0.0101,  0.1960,\n",
      "         -0.1381, -0.2024],\n",
      "        [-0.2614, -0.1803, -0.0842, -0.1633, -0.2948, -0.2351, -0.1535,  0.0328,\n",
      "          0.1041, -0.2271],\n",
      "        [-0.0740, -0.1019, -0.1200, -0.2486, -0.2470,  0.1968,  0.1455,  0.1978,\n",
      "          0.0940, -0.1829],\n",
      "        [ 0.1720, -0.0774,  0.0181, -0.3142,  0.1556,  0.0076, -0.2390, -0.1603,\n",
      "         -0.1067,  0.2032],\n",
      "        [-0.0384,  0.2354, -0.0733, -0.1160, -0.0572, -0.2430,  0.1680,  0.0472,\n",
      "          0.1486, -0.1304],\n",
      "        [ 0.2892, -0.0399,  0.0911, -0.2712,  0.2287,  0.2710, -0.1434,  0.0028,\n",
      "         -0.0032, -0.1079],\n",
      "        [ 0.1450, -0.1553,  0.1262,  0.0956, -0.2930,  0.2795,  0.1697, -0.0815,\n",
      "         -0.0773,  0.1519],\n",
      "        [ 0.0539,  0.0055,  0.2937,  0.1953,  0.1133, -0.0424, -0.1616, -0.3092,\n",
      "          0.2054, -0.2970]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2643, -0.2650,  0.2434, -0.2140,  0.1217,  0.2840, -0.0452,  0.1868,\n",
      "        -0.2930, -0.0182], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.2402, -0.2005,  0.0242,  0.0152,  0.2095,  0.2634,  0.2856,  0.0079,\n",
      "         -0.2737, -0.0826],\n",
      "        [-0.2755, -0.1030, -0.0487, -0.0040, -0.2505, -0.0333,  0.2844, -0.1374,\n",
      "         -0.0291,  0.0625],\n",
      "        [-0.0353, -0.2273, -0.2835,  0.1706,  0.2546, -0.2128,  0.0411, -0.2142,\n",
      "         -0.1993,  0.1012],\n",
      "        [-0.0721, -0.2900,  0.3009, -0.2192,  0.0639,  0.0305,  0.1125,  0.1788,\n",
      "          0.2893, -0.1352],\n",
      "        [ 0.2561,  0.3099,  0.1217,  0.1576,  0.1460,  0.0301, -0.0713, -0.1999,\n",
      "         -0.2484, -0.2724],\n",
      "        [ 0.2881, -0.1864,  0.2658, -0.0638,  0.1626,  0.1790, -0.1252,  0.1917,\n",
      "          0.2618,  0.0007],\n",
      "        [-0.2025,  0.1591, -0.1833, -0.2451,  0.1158,  0.1049, -0.2339, -0.0759,\n",
      "          0.1749,  0.2073],\n",
      "        [ 0.0144, -0.0091,  0.0762, -0.1074, -0.2228, -0.2393,  0.0719,  0.2135,\n",
      "         -0.0191,  0.0368]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1593, -0.2995, -0.2896, -0.2600,  0.2816, -0.1820, -0.2106, -0.3174],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0869, -0.3203, -0.1135, -0.2838,  0.2425,  0.3468,  0.0033,  0.1827],\n",
      "        [ 0.3330,  0.3268, -0.1922,  0.1139, -0.0178, -0.0942, -0.0760,  0.1693],\n",
      "        [-0.1705, -0.2996, -0.1501, -0.2206,  0.0187, -0.3176,  0.3235,  0.2911],\n",
      "        [ 0.2568, -0.2603, -0.0027, -0.0341, -0.2209,  0.3316, -0.2705, -0.2794],\n",
      "        [ 0.3374, -0.2367,  0.1907, -0.2085,  0.1898,  0.0702,  0.0456, -0.2148],\n",
      "        [-0.0084, -0.1267, -0.2730, -0.2161, -0.2994,  0.3116, -0.0566, -0.1761]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2723, 0.1547, 0.2172, 0.2924, 0.3638, 0.0435], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1146, -0.2373, -0.0691,  0.2667,  0.2116, -0.3808]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0713], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for index in range(nb_epochs):\n",
    "    indices = torch.randperm(x.size(0))\n",
    "\n",
    "    x_batch_list = torch.index_select(x, 0, index=indices)\n",
    "    y_batch_list = torch.index_select(y, 0, index=indices)\n",
    "    x_batch_list = x_batch_list.split(minibatch_size, dim=0)\n",
    "    y_batch_list = y_batch_list.split(minibatch_size, dim=0)\n",
    "\n",
    "    for x_minibatch, y_minibatch in zip(x_batch_list, y_batch_list):\n",
    "        y_minibatch_pred = model(x_minibatch)\n",
    "        loss = loss_function(y_minibatch_pred, y_minibatch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print(loss)\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
