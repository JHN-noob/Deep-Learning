Cross Entropy Loss Function

두 확률분포의 차이를 계산하는 손실함수
실제 데이터의 분포를 원핫인코딩으로 표현했을 때와 모델이 계산한 확률의 차이를 계산한다.
H(P, Q) = -(P(n) * logQ(n)의 총합)
H(P, Q) = -((0 * log0.15) + (1 * log0.65) + (0 * log0.20))
  ※ 앞단에 -를 붙이는 이유는 0~1 사이의 log값은 음수이기 때문(양수로 변환)
